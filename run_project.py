#!/usr/bin/env python3
"""
AI Overview Projesi - Ana Ã‡alÄ±ÅŸtÄ±rma Scripti
Proje sÃ¼reÃ§lerini yÃ¶netir ve koordine eder.
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Optional

# Proje kÃ¶k dizinini sys.path'e ekle
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# Proje modÃ¼llerini import et
try:
    from scripts.data_extractor import WebsiteDataExtractor
    from scripts.batch_processor import BatchProcessor
    from scripts.vertex_ai_setup import VertexAISetup
    from scripts.search_engine_builder import SearchEngineBuilder
    from config.settings import *
except ImportError as e:
    print(f"âŒ Proje modÃ¼lleri yÃ¼klenemedi: {e}")
    print("LÃ¼tfen requirements.txt'i yÃ¼klediÄŸinizden emin olun:")
    print("pip install -r requirements.txt")
    sys.exit(1)

# Loglama konfigÃ¼rasyonu
logging.basicConfig(
    level=LOG_LEVEL,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(project_root / 'logs' / 'main.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def step_1_extract_website_data(url: str, max_pages: int = 100) -> bool:
    """AdÄ±m 1: Web sitesinden veri Ã§Ä±karma"""
    print("ğŸš€ ADIM 1: Web Sitesi Veri Ã‡Ä±karma")
    print(f"Hedef URL: {url}")
    print(f"Maksimum sayfa: {max_pages}")
    print("-" * 50)
    
    try:
        extractor = WebsiteDataExtractor(url, max_pages)
        
        # Sitemap analizi
        print("ğŸ“‹ Sitemap analizi yapÄ±lÄ±yor...")
        urls = extractor.discover_urls()
        print(f"âœ… {len(urls)} URL keÅŸfedildi")
        
        # Ä°Ã§erik Ã§Ä±karma
        print("ğŸ“„ Ä°Ã§erik Ã§Ä±karÄ±lÄ±yor...")
        data = extractor.extract_content_from_urls(urls)
        
        # Verileri kaydet
        output_file = extractor.save_extracted_data(data)
        print(f"âœ… Veriler kaydedildi: {output_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"Veri Ã§Ä±karma hatasÄ±: {str(e)}")
        print(f"âŒ Hata: {str(e)}")
        return False

def step_2_process_batches(raw_data_file: Path) -> List[Path]:
    """AdÄ±m 2: Verileri batch'lere bÃ¶l"""
    print("\nğŸ”„ ADIM 2: Batch Ä°ÅŸleme")
    print(f"Ham veri dosyasÄ±: {raw_data_file}")
    print("-" * 50)
    
    try:
        processor = BatchProcessor()
        
        # Ham verileri yÃ¼kle
        print("ğŸ“‚ Ham veriler yÃ¼kleniyor...")
        raw_data = processor.load_raw_data(raw_data_file)
        print(f"âœ… {len(raw_data)} kayÄ±t yÃ¼klendi")
        
        # Batch'lere bÃ¶l
        print("âœ‚ï¸ Batch'lere bÃ¶lÃ¼nÃ¼yor...")
        batch_files = processor.create_batches(raw_data)
        print(f"âœ… {len(batch_files)} batch oluÅŸturuldu")
        
        return batch_files
        
    except Exception as e:
        logger.error(f"Batch iÅŸleme hatasÄ±: {str(e)}")
        print(f"âŒ Hata: {str(e)}")
        return []

def step_3_setup_vertex_ai(batch_files: List[Path]) -> Dict[str, str]:
    """AdÄ±m 3: Vertex AI kurulumu"""
    print("\nâ˜ï¸ ADIM 3: Vertex AI Kurulumu")
    print(f"{len(batch_files)} batch dosyasÄ± iÅŸlenecek")
    print("-" * 50)
    
    try:
        vertex_setup = VertexAISetup()
        
        # Cloud Storage bucket oluÅŸtur
        print("ğŸ—‚ï¸ Cloud Storage bucket oluÅŸturuluyor...")
        bucket_created = vertex_setup.create_storage_bucket()
        if bucket_created:
            print("âœ… Bucket oluÅŸturuldu")
        
        # Batch dosyalarÄ±nÄ± Cloud Storage'a yÃ¼kle
        print("â¬†ï¸ Batch dosyalarÄ± yÃ¼kleniyor...")
        upload_success = vertex_setup.upload_batch_files(batch_files)
        if not upload_success:
            print("âŒ Dosya yÃ¼kleme baÅŸarÄ±sÄ±z!")
            return {}
        
        # Data store oluÅŸtur
        print("ğŸ“Š Data store oluÅŸturuluyor...")
        data_store_id = vertex_setup.create_data_store()
        if not data_store_id:
            print("âŒ Data store oluÅŸturulamadÄ±!")
            return {}
        
        # Search engine oluÅŸtur
        print("ğŸ” Search engine oluÅŸturuluyor...")
        engine_id = vertex_setup.create_search_engine(data_store_id)
        if not engine_id:
            print("âŒ Search engine oluÅŸturulamadÄ±!")
            return {}
        
        print("âœ… Vertex AI kurulumu tamamlandÄ±!")
        
        return {
            'data_store_id': data_store_id,
            'engine_id': engine_id
        }
        
    except Exception as e:
        logger.error(f"Vertex AI kurulum hatasÄ±: {str(e)}")
        print(f"âŒ Hata: {str(e)}")
        return {}

def step_4_import_and_analyze(engine_id: str, data_store_id: str, batch_files: List[Path], 
                             query: str, keywords: List[str]) -> bool:
    """AdÄ±m 4: Import ve AI Overview analizi"""
    print("\nğŸ¤– ADIM 4: Import ve AI Overview Analizi")
    print(f"Search Engine ID: {engine_id}")
    print(f"Data Store ID: {data_store_id}")
    print(f"Arama sorgusu: {query}")
    print(f"Hedef kelimeler: {', '.join(keywords)}")
    print("-" * 50)
    
    try:
        builder = SearchEngineBuilder()
        
        # DokÃ¼manlarÄ± import et
        print("ğŸ“¥ DokÃ¼manlar import ediliyor...")
        import_success = builder.import_documents_to_datastore(data_store_id, batch_files)
        if not import_success:
            print("âŒ Import baÅŸarÄ±sÄ±z!")
            return False
        
        print("â³ Import iÅŸleminin tamamlanmasÄ± bekleniyor (5 dakika)...")
        import time
        time.sleep(300)  # 5 dakika bekle
        
        # Arama testi
        print("ğŸ” Arama testi yapÄ±lÄ±yor...")
        search_results = builder.search_documents(engine_id, query)
        
        if not search_results.get('results'):
            print("âš ï¸ HenÃ¼z arama sonucu yok, daha fazla bekleme gerekebilir")
            print("Import iÅŸleminin tamamlanmasÄ± 30 dakika kadar sÃ¼rebilir")
            return True
        
        # AI Overview analizi
        print("ğŸ§  AI Overview analizi yapÄ±lÄ±yor...")
        analysis = builder.analyze_ai_overview_potential(search_results, keywords)
        
        # SonuÃ§larÄ± kaydet
        result_file = builder.save_analysis_results(analysis, search_results)
        
        # Ã–zet rapor
        print("\nğŸ“Š ANALIZ SONUÃ‡LARI")
        print("=" * 50)
        print(f"AI Overview Skoru: {analysis.get('ai_overview_score', 0):.1%}")
        print(f"Ä°Ã§erik Kalitesi: {analysis.get('content_quality_score', 0):.1%}")
        print(f"Anahtar Kelime Uyumu: {analysis.get('keyword_relevance_score', 0):.1%}")
        print(f"Bulunan DokÃ¼man: {len(search_results.get('results', []))}")
        
        print("\nğŸ’¡ Ã–NERÄ°LER:")
        recommendations = analysis.get('recommendations', [])
        for i, rec in enumerate(recommendations[:3], 1):
            print(f"{i}. {rec}")
        
        print(f"\nğŸ“ DetaylÄ± rapor: {result_file}")
        
        return True
        
    except Exception as e:
        logger.error(f"Import ve analiz hatasÄ±: {str(e)}")
        print(f"âŒ Hata: {str(e)}")
        return False

def main():
    """Ana fonksiyon"""
    parser = argparse.ArgumentParser(description='AI Overview Optimization Projesi')
    parser.add_argument('--url', required=True, help='Hedef web sitesi URL\'i')
    parser.add_argument('--query', required=True, help='Test arama sorgusu')
    parser.add_argument('--keywords', nargs='+', required=True, help='Hedef anahtar kelimeler')
    parser.add_argument('--max-pages', type=int, default=100, help='Maksimum sayfa sayÄ±sÄ± (varsayÄ±lan: 100)')
    parser.add_argument('--skip-extract', action='store_true', help='Veri Ã§Ä±karmayÄ± atla')
    parser.add_argument('--skip-vertex', action='store_true', help='Vertex AI kurulumunu atla')
    parser.add_argument('--raw-data-file', help='Mevcut ham veri dosyasÄ± (veri Ã§Ä±karma atlanÄ±rsa)')
    parser.add_argument('--engine-id', help='Mevcut search engine ID (Vertex AI kurulumu atlanÄ±rsa)')
    parser.add_argument('--data-store-id', help='Mevcut data store ID (Vertex AI kurulumu atlanÄ±rsa)')
    
    args = parser.parse_args()
    
    print("ğŸ¯ AI OVERVIEW OPTÄ°MÄ°ZASYON PROJESÄ°")
    print("=" * 60)
    print(f"Hedef URL: {args.url}")
    print(f"Arama sorgusu: {args.query}")
    print(f"Hedef kelimeler: {', '.join(args.keywords)}")
    print(f"Maksimum sayfa: {args.max_pages}")
    print("=" * 60)
    
    try:
        # AdÄ±m 1: Veri Ã§Ä±karma
        raw_data_file = None
        if not args.skip_extract:
            success = step_1_extract_website_data(args.url, args.max_pages)
            if not success:
                print("âŒ Proje durduruldu: Veri Ã§Ä±karma baÅŸarÄ±sÄ±z")
                return
            
            # En son oluÅŸturulan ham veri dosyasÄ±nÄ± bul
            raw_data_files = list(RAW_DATA_DIR.glob("website_data_*.json"))
            if raw_data_files:
                raw_data_file = max(raw_data_files, key=lambda f: f.stat().st_mtime)
        else:
            if args.raw_data_file:
                raw_data_file = Path(args.raw_data_file)
                if not raw_data_file.exists():
                    print(f"âŒ Ham veri dosyasÄ± bulunamadÄ±: {raw_data_file}")
                    return
            else:
                # En son oluÅŸturulan dosyayÄ± bul
                raw_data_files = list(RAW_DATA_DIR.glob("website_data_*.json"))
                if raw_data_files:
                    raw_data_file = max(raw_data_files, key=lambda f: f.stat().st_mtime)
                else:
                    print("âŒ Ham veri dosyasÄ± bulunamadÄ±. --raw-data-file parametresini kullanÄ±n.")
                    return
        
        # AdÄ±m 2: Batch iÅŸleme
        batch_files = step_2_process_batches(raw_data_file)
        if not batch_files:
            print("âŒ Proje durduruldu: Batch iÅŸleme baÅŸarÄ±sÄ±z")
            return
        
        # AdÄ±m 3: Vertex AI kurulumu
        engine_id = args.engine_id
        data_store_id = args.data_store_id
        
        if not args.skip_vertex:
            vertex_result = step_3_setup_vertex_ai(batch_files)
            if not vertex_result:
                print("âŒ Proje durduruldu: Vertex AI kurulumu baÅŸarÄ±sÄ±z")
                return
            
            engine_id = vertex_result['engine_id']
            data_store_id = vertex_result['data_store_id']
        else:
            if not engine_id or not data_store_id:
                print("âŒ --engine-id ve --data-store-id parametreleri gerekli (Vertex AI kurulumu atlandÄ±ÄŸÄ±nda)")
                return
        
        # AdÄ±m 4: Import ve analiz
        success = step_4_import_and_analyze(
            engine_id, data_store_id, batch_files, 
            args.query, args.keywords
        )
        
        if success:
            print("\nğŸ‰ PROJE BAÅARIYLA TAMAMLANDI!")
            print("=" * 50)
            print(f"Search Engine ID: {engine_id}")
            print(f"Data Store ID: {data_store_id}")
            print("Google Cloud Console'dan ilerleyiÅŸi takip edebilirsiniz.")
        else:
            print("\nâŒ Proje tamamlanamadÄ±!")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Proje kullanÄ±cÄ± tarafÄ±ndan durduruldu")
    except Exception as e:
        logger.error(f"Genel hata: {str(e)}")
        print(f"\nâŒ Beklenmeyen hata: {str(e)}")

if __name__ == "__main__":
    main() 